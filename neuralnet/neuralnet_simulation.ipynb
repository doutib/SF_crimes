{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from neuralnet_function import *\n",
    "from multiprocessing import Pool, TimeoutError\n",
    "from multiprocessing import cpu_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## # Collect data\n",
    "df = pd.DataFrame.from_csv(\"data/data_train.csv\", index_col = None)\n",
    "## # Separate labels from data\n",
    "X = df.drop(['Category'], axis = 1)\n",
    "Y = df[['Category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   prop_train method1  neurons1 method2  neurons2   decay  learning_rate  \\\n",
      "0         0.5    Tanh         1    None         0  0.0001          0.001   \n",
      "1         0.5    Tanh         1    None         0  0.0001          0.001   \n",
      "\n",
      "   n_iter  random_state  \n",
      "0      25             1  \n",
      "1      25             2  \n"
     ]
    }
   ],
   "source": [
    "# Import set of global parameters from parameters.csv\n",
    "parameters_filename = \"data/neuralnet_parameters.csv\"\n",
    "\n",
    "# Import parameters\n",
    "df_parameters = pd.DataFrame.from_csv(parameters_filename, index_col = None)\n",
    "indexes = np.arange(df_parameters.shape[0]) \n",
    "print df_parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def processInput(index): \n",
    "    # Load parameters\n",
    "    parameters = np.array(df_parameters.iloc[[index]])[0]\n",
    "    # Define parameters\n",
    "    prop_train,method1,neurons1,method2,neurons2,decay,learning_rate,n_iter,random_state=parameters\n",
    "    # Run nnet\n",
    "    result = two_layers_nnet(X,\n",
    "                             Y,\n",
    "                             prop_train,\n",
    "                             method1,\n",
    "                             neurons1,\n",
    "                             method2,\n",
    "                             neurons2,\n",
    "                             decay,\n",
    "                             learning_rate,\n",
    "                             n_iter,\n",
    "                             random_state)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of identified clusters: 8.\n"
     ]
    }
   ],
   "source": [
    "## Parallelization parameters\n",
    "num_cpu = cpu_count()          # Number of clusters\n",
    "print \"Number of identified clusters: %s.\" %num_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start clusters...\n"
     ]
    }
   ],
   "source": [
    "print 'Start clusters...'\n",
    "pool = Pool(processes=num_cpu)                 # Start clusters  \n",
    "results = pool.map(processInput, indexes) \n",
    "pool.terminate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results:\n",
      "--------\n",
      "[array(['2.65834308081', '0.78827577866', '0.21172422134', '0.21172422134',\n",
      "       '0.21172422134', 'Tanh', '1', 'None', '0', '0.0001', '0.001', '25',\n",
      "       '1', '0.5'], \n",
      "      dtype='|S32'), array(['2.65574890056', '0.78692942602', '0.21307057398', '0.21307057398',\n",
      "       '0.21307057398', 'Tanh', '1', 'None', '0', '0.0001', '0.001', '25',\n",
      "       '2', '0.5'], \n",
      "      dtype='|S32')]\n"
     ]
    }
   ],
   "source": [
    "print 'Results:\\n--------'\n",
    "print results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Open file\n",
    "with open('data/neuralnet_results.csv', 'wb') as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow( [\"logloss\",\n",
    "                       \"miss_err\",\n",
    "                       \"prec\",\n",
    "                       \"recall\",\n",
    "                       \"f1\",\n",
    "                       \"method1\",\n",
    "                       \"neurons1\",\n",
    "                       \"method2\",\n",
    "                       \"neurons2\",\n",
    "                       \"decay\",\n",
    "                       \"learning_rate\",\n",
    "                       \"n_iter\",\n",
    "                       \"random_state\",\n",
    "                       \"prop_train\"] )\n",
    "    writer.writerows(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
